{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8f2581",
   "metadata": {},
   "source": [
    "#  PikaPikaGenerator - Data Preprocessing\n",
    "# \n",
    "**Progetto:** Generative Synthesis of Pokémon Sprites from Textual Descriptions  \n",
    " **Corso:** Deep Learning - Politecnico di Bari  \n",
    " **Studente:** Pasquale Alessandro Denora  \n",
    " **Professore:** Vito Walter Anelli "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c00d1e",
   "metadata": {},
   "source": [
    "#   Import e Setup Iniziale\n",
    " \n",
    " Il file inizia importando tutte le librerie necessarie per il preprocessing dei dati Pokemon. Le librerie principali includono:\n",
    " - **pandas**: per manipolare il CSV con i dati Pokemon\n",
    " - **PIL**: per caricare e validare le immagini sprite  \n",
    " - **torch**: per creare Dataset e DataLoader PyTorch\n",
    " - **transformers**: per il tokenizer BERT\n",
    " - **pathlib**: per gestire i percorsi dei file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3384eec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43420bf",
   "metadata": {},
   "source": [
    "#  Classe PokemonDataProcessor - Inizializzazione\n",
    " \n",
    " La classe principale `PokemonDataProcessor` gestisce tutto il processo di preprocessing. Nel costruttore (righe 21-25) vengono inizializzati:\n",
    " - `self.config`: la configurazione del progetto\n",
    " - `self.df`: il DataFrame pandas (inizialmente None)\n",
    " - `self.tokenizer`: il tokenizer BERT (inizialmente None)  \n",
    " - `self.stats`: dizionario per raccogliere statistiche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab9b80",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class PokemonDataProcessor:\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.df = None\n",
    "        self.tokenizer = None\n",
    "        self.stats = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793e0ee",
   "metadata": {},
   "source": [
    "#   Caricamento e Validazione CSV\n",
    "\n",
    " Il metodo `load_and_validate_data()` (righe 27-66) carica il file CSV Pokemon. La strategia è robusta:\n",
    " \n",
    " 1. **Prova multiple encoding** (righe 32-46): Il file potrebbe avere encoding diversi, quindi prova in sequenza utf-16, utf-8, cp1252, latin1\n",
    " 2. **Separatore tab** (riga 38): Usa `sep='\\t'` perché il file è tab-separated\n",
    " 3. **Validazione colonne** (righe 49-52): Verifica che esistano le colonne richieste\n",
    " 4. **Pulizia dati** (righe 55-60): Rimuove righe senza descrizione o con descrizioni troppo corte (<10 caratteri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c25848",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_validate_data(self) -> pd.DataFrame:\n",
    "    \"\"\"Load and validate Pokemon CSV data\"\"\"\n",
    "    logger.info(\"Loading Pokemon dataset...\")\n",
    "    \n",
    "    # prova più encodings \n",
    "    encodings = ['utf-16', 'utf-8', 'cp1252', 'latin1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            self.df = pd.read_csv(\n",
    "                self.config['data']['raw_data_path'], \n",
    "                encoding=encoding,\n",
    "                sep='\\t'\n",
    "            )\n",
    "            logger.info(f\"Successfully loaded with encoding: {encoding}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if self.df is None:\n",
    "        raise ValueError(\"Could not load CSV with any encoding\")\n",
    "    \n",
    "    # Convalida le columns\n",
    "    required_cols = ['description', 'english_name', 'national_number']\n",
    "    missing_cols = [col for col in required_cols if col not in self.df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Pulisce i data\n",
    "    initial_count = len(self.df)\n",
    "    self.df = self.df.dropna(subset=['description'])\n",
    "    self.df = self.df[self.df['description'].str.len() > 10]  # Rimuovi descrizioni troppo corte\n",
    "    final_count = len(self.df)\n",
    "    \n",
    "    logger.info(f\"Loaded {final_count} valid Pokemon (removed {initial_count - final_count})\")\n",
    "    \n",
    "    # Store statistics\n",
    "    self.stats['total_pokemon'] = final_count\n",
    "    self.stats['description_lengths'] = self.df['description'].str.len().describe().to_dict()\n",
    "    \n",
    "    return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92095c03",
   "metadata": {},
   "source": [
    "#   Validazione Immagini Pokemon\n",
    "\n",
    " Il metodo `validate_images()` (righe 68-109) è cruciale perché verifica che ogni Pokemon nel CSV abbia un'immagine corrispondente:\n",
    " \n",
    " 1. **Percorsi multipli** (righe 80-84): Per ogni Pokemon prova diversi formati di nome file:\n",
    "    - `001.png` (numero con zero padding) \n",
    "    - `small_images/001.png` (sottodirectory)\n",
    "    - `1.png` (numero senza padding)\n",
    " \n",
    " 2. **Validazione integrità** (righe 91-95): Non basta che il file esista, deve essere un'immagine valida\n",
    "    - Usa `Image.open()` e `img.verify()` per controllare l'integrità\n",
    " \n",
    " 3. **Tracciamento risultati**: Mantiene un dizionario delle immagini valide e una lista di quelle mancanti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ddb68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def validate_images(self) -> Dict[int, str]:\n",
    "    \"\"\"Validate available images and create mapping\"\"\"\n",
    "    logger.info(\"Validating Pokemon images...\")\n",
    "    \n",
    "    images_dir = Path(self.config['data']['images_dir'])\n",
    "    valid_images = {}\n",
    "    missing_images = []\n",
    "    \n",
    "    for idx, row in tqdm(self.df.iterrows(), total=len(self.df), desc=\"Validating images\"):\n",
    "        national_number = int(row['national_number'])\n",
    "        \n",
    "        # Controlla possibili percorsi dell'immagine\n",
    "        possible_paths = [\n",
    "            images_dir / f\"{national_number:03d}.png\",\n",
    "            images_dir / \"small_images\" / f\"{national_number:03d}.png\",\n",
    "            images_dir / f\"{national_number}.png\"\n",
    "        ]\n",
    "        \n",
    "        image_found = False\n",
    "        for img_path in possible_paths:\n",
    "            if img_path.exists():\n",
    "                try:\n",
    "                    # Valida immagini che siano immagini valide\n",
    "                    img = Image.open(img_path)\n",
    "                    img.verify()\n",
    "                    valid_images[idx] = str(img_path)\n",
    "                    image_found = True\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if not image_found:\n",
    "            missing_images.append(national_number)\n",
    "    \n",
    "    logger.info(f\"Found {len(valid_images)} valid images\")\n",
    "    if missing_images:\n",
    "        logger.warning(f\"Missing images for {len(missing_images)} Pokemon: {missing_images[:10]}...\")\n",
    "    \n",
    "    self.stats['valid_images'] = len(valid_images)\n",
    "    self.stats['missing_images'] = len(missing_images)\n",
    "    \n",
    "    return valid_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c282a",
   "metadata": {},
   "source": [
    "#   Creazione Split Train/Validation/Test\n",
    "\n",
    " Il metodo `create_splits()` (righe 111-138) divide il dataset in tre parti per il machine learning:\n",
    " \n",
    " 1. **Filtraggio** (riga 116): Lavora solo sui Pokemon che hanno immagini valide\n",
    " 2. **Shuffling riproducibile** (righe 119-121): \n",
    "    - Imposta il seed da config per riproducibilità\n",
    "    - Mischia gli indici in modo random ma deterministic\n",
    " 3. **Calcolo proporzioni** (righe 124-126): Calcola le dimensioni basandosi sui parametri in config:\n",
    "    - `config['data']['train_split']` (es. 0.8 = 80%)\n",
    "    - `config['data']['val_split']` (es. 0.1 = 10%)\n",
    "    - Il resto va automaticamente a test\n",
    " 4. **Slicing sequenziale**: Divide la lista shuffled in tre parti consecutive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4dbd8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_splits(self, valid_indices: List[int]) -> Dict[str, List[int]]:\n",
    "    \"\"\"Create train/val/test splits\"\"\"\n",
    "    logger.info(\"Creating data splits...\")\n",
    "    \n",
    "    # Filter to only valid entries\n",
    "    valid_df = self.df.loc[valid_indices]\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = valid_df.index.tolist()\n",
    "    np.random.seed(self.config['project']['seed'])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    n_total = len(indices)\n",
    "    n_train = int(n_total * self.config['data']['train_split'])\n",
    "    n_val = int(n_total * self.config['data']['val_split'])\n",
    "    \n",
    "    # Create splits\n",
    "    splits = {\n",
    "        'train': indices[:n_train],\n",
    "        'val': indices[n_train:n_train + n_val],\n",
    "        'test': indices[n_train + n_val:]\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Split sizes - Train: {len(splits['train'])}, \"\n",
    "               f\"Val: {len(splits['val'])}, Test: {len(splits['test'])}\")\n",
    "    \n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f5f80c",
   "metadata": {},
   "source": [
    "#   Salvataggio Dati Processati\n",
    "\n",
    " Il metodo `save_processed_data()` (righe 140-160) salva tutto il lavoro fatto in file JSON e CSV:\n",
    " \n",
    " 1. **Creazione directory** (righe 143): Crea la directory di output se non esiste\n",
    " 2. **File salvati**:\n",
    "    - `valid_images.json`: mappa indice → percorso immagine\n",
    "    - `splits.json`: indici per train/val/test  \n",
    "    - `processed_pokemon.csv`: DataFrame pulito\n",
    "    - `dataset_stats.json`: statistiche complete\n",
    " \n",
    " Tutti i percorsi usano `config['data']['processed_data_path']` come directory base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eba41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_processed_data(self, valid_images: Dict, splits: Dict):\n",
    "    \"\"\"Save processed data and metadata\"\"\"\n",
    "    output_dir = Path(self.config['data']['processed_data_path'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Salva mappatura delle immagini valide\n",
    "    with open(output_dir / 'valid_images.json', 'w') as f:\n",
    "        json.dump(valid_images, f)\n",
    "    \n",
    "    # Salva gli indici delle suddivisioni\n",
    "    with open(output_dir / 'splits.json', 'w') as f:\n",
    "        json.dump(splits, f)\n",
    "    \n",
    "    # Salva il dataframe processato\n",
    "    self.df.to_csv(output_dir / 'processed_pokemon.csv', index=True)\n",
    "    \n",
    "    # Salva le statistiche del dataset\n",
    "    with open(output_dir / 'dataset_stats.json', 'w') as f:\n",
    "        json.dump(self.stats, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Saved processed data to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539a771",
   "metadata": {},
   "source": [
    "#  Pipeline Completa di Preprocessing\n",
    " \n",
    " Il metodo `process()` (righe 162-180) orchestra l'intera pipeline:\n",
    " \n",
    " 1. Carica e valida il CSV\n",
    " 2. Valida tutte le immagini  \n",
    " 3. Crea gli split train/val/test\n",
    " 4. Salva tutto nei file di output\n",
    " \n",
    " È il metodo principale che viene chiamato da `main.py` quando si esegue il preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2f94f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process(self):\n",
    "    \"\"\"Run complete preprocessing pipeline\"\"\"\n",
    "    logger.info(\"Starting data preprocessing...\")\n",
    "    \n",
    "    # Carica e valida i dati\n",
    "    self.load_and_validate_data()\n",
    "    \n",
    "    # Convalida le immagini\n",
    "    valid_images = self.validate_images()\n",
    "    valid_indices = list(valid_images.keys())\n",
    "    \n",
    "    # Crea le suddivisioni\n",
    "    splits = self.create_splits(valid_indices)\n",
    "    \n",
    "    # Salva i dati processati\n",
    "    self.save_processed_data(valid_images, splits)\n",
    "    \n",
    "    logger.info(\"Data preprocessing completed!\")\n",
    "    return self.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c288ea1",
   "metadata": {},
   "source": [
    "#   Classe PokemonDataset per PyTorch\n",
    "\n",
    " La classe `PokemonDataset` (righe 183-223) eredita da `torch.utils.data.Dataset` e prepara i dati per il training:\n",
    " \n",
    " **Inizializzazione (righe 200-226)**:\n",
    " - Carica i dati processati dai file JSON/CSV salvati prima\n",
    " - Inizializza il tokenizer BERT specificato in config\n",
    " - Configura le trasformazioni per le immagini\n",
    " \n",
    " **Parametri importanti**:\n",
    " - `image_size`: dimensione target per le immagini (da config)\n",
    " - `max_length`: lunghezza massima sequenze per il tokenizer\n",
    " - `augment`: se applicare data augmentation (solo per training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51db31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for Pokemon sprite generation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        data_path: str,\n",
    "        split: str,\n",
    "        tokenizer_name: str,\n",
    "        max_length: int = 128,\n",
    "        image_size: int = 215,\n",
    "        augment: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.max_length = max_length\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Carica i dati processati\n",
    "        processed_dir = Path(data_path)\n",
    "        \n",
    "        # Carica il dataframe \n",
    "        self.df = pd.read_csv(processed_dir / 'processed_pokemon.csv', index_col=0)\n",
    "        \n",
    "        # Carica la mappatura delle immagini valide\n",
    "        with open(processed_dir / 'valid_images.json', 'r') as f:\n",
    "            self.valid_images = {int(k): v for k, v in json.load(f).items()}\n",
    "        \n",
    "        # Carica le suddivisioni\n",
    "        with open(processed_dir / 'splits.json', 'r') as f:\n",
    "            splits = json.load(f)\n",
    "            self.indices = splits[split]\n",
    "        \n",
    "        # Inizializza il tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        \n",
    "        # Setta le trasformazioni delle immagini\n",
    "        self._setup_transforms()\n",
    "        \n",
    "        logger.info(f\"Loaded {split} dataset with {len(self.indices)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d779c",
   "metadata": {},
   "source": [
    "#   Setup Trasformazioni Immagini\n",
    "\n",
    " Il metodo `_setup_transforms()` (righe 224-246) configura come preprocessare le immagini:\n",
    " \n",
    " **Trasformazioni base** (sempre applicate):\n",
    " - `Resize`: ridimensiona a dimensione target\n",
    " - `ToTensor`: converte PIL Image in tensor PyTorch  \n",
    " - `Normalize`: normalizza pixel da [0,1] a [-1,1] usando mean=0.5, std=0.5\n",
    " \n",
    " **Data Augmentation** (solo per training):\n",
    " - `RandomCrop`: crop casuale dopo resize più grande\n",
    " - `RandomHorizontalFlip`: flip orizzontale casuale\n",
    " - `ColorJitter`: variazioni casuali di luminosità, contrasto, saturazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450f99d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def _setup_transforms(self):\n",
    "    \"\"\"Setup image transformations\"\"\"\n",
    "    import torchvision.transforms as transforms\n",
    "    \n",
    "    # Definisci le trasformazioni di base\n",
    "    basic_transforms = [\n",
    "        transforms.Resize((self.image_size, self.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ]\n",
    "    \n",
    "    if self.augment and self.split == 'train':\n",
    "        # Aggiungi trasformazioni di data augmentation\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size + 20, self.image_size + 20)),\n",
    "            transforms.RandomCrop(self.image_size),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    else:\n",
    "        self.transform = transforms.Compose(basic_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cd87c",
   "metadata": {},
   "source": [
    "#   Metodo __getitem__ - Caricamento Singolo Sample\n",
    "\n",
    " Il metodo `__getitem__()` (righe 251-285) è chiamato dal DataLoader per ottenere un singolo sample:\n",
    " \n",
    " **Processo step-by-step**:\n",
    " 1. **Recupera dati Pokemon** (righe 253-254): Usa l'indice per ottenere la riga corrispondente dal DataFrame\n",
    " 2. **Carica immagine** (righe 257-258): Apre l'immagine dal percorso salvato\n",
    " 3. **Gestione trasparenza** (righe 260-264): Converte RGBA→RGB usando background bianco\n",
    " 4. **Trasformazioni** (riga 266): Applica resize, normalizzazione, augmentation\n",
    " 5. **Tokenizzazione testo** (righe 269-276): Tokenizza la descrizione Pokemon con padding/truncation\n",
    " \n",
    " **Output**: Dizionario con image tensor, token IDs, attention mask, testo originale, nome Pokemon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d723ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    # Ottiene l'indice del dataframe\n",
    "    df_idx = self.indices[idx]\n",
    "    row = self.df.loc[df_idx]\n",
    "    \n",
    "    # Carica e processa l'immagine\n",
    "    image_path = self.valid_images[df_idx]\n",
    "    image = Image.open(image_path).convert('RGBA')\n",
    "    \n",
    "    # Converti RGBA a RGB se necessario\n",
    "    if image.mode == 'RGBA':\n",
    "        background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "        background.paste(image, mask=image.split()[3])\n",
    "        image = background\n",
    "    \n",
    "    image = self.transform(image)\n",
    "    \n",
    "    # Tokenizza il testo\n",
    "    text = row['description']\n",
    "    encoding = self.tokenizer(\n",
    "        text,\n",
    "        max_length=self.max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'image': image,\n",
    "        'input_ids': encoding['input_ids'].squeeze(0),\n",
    "        'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "        'text': text,\n",
    "        'name': row['english_name'],\n",
    "        'idx': df_idx\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cc920",
   "metadata": {},
   "source": [
    "#   Funzione create_dataloaders\n",
    " \n",
    " La funzione `create_dataloaders()` (righe 290-316) crea i DataLoader PyTorch per train/val/test:\n",
    " \n",
    " **Configurazione per ogni split**:\n",
    " - Legge `image_size` da config con fallback a 215\n",
    " - Crea PokemonDataset per ogni split (train/val/test)\n",
    " - Applica augmentation solo al training set\n",
    " \n",
    " **Parametri DataLoader** (da config):\n",
    " - `batch_size`: numero di sample per batch\n",
    " - `num_workers`: processi per caricamento parallelo\n",
    " - `shuffle=True` solo per training\n",
    " - `pin_memory=True` se GPU disponibile (ottimizzazione)\n",
    " - `drop_last=True` solo per training (batch uniformi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48ddde",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(config: Dict, tokenizer_name: str) -> Dict[str, DataLoader]:\n",
    "    \"\"\"Create dataloaders for all splits\"\"\"\n",
    "    dataloaders = {}\n",
    "    \n",
    "    # Leggi image_size dal config con fallback\n",
    "    image_size = config.get('data', {}).get('image_size', 215)\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        dataset = PokemonDataset(\n",
    "            data_path=config['data']['processed_data_path'],\n",
    "            split=split,\n",
    "            tokenizer_name=tokenizer_name,\n",
    "            max_length=config['model']['encoder']['max_length'],\n",
    "            image_size=image_size,\n",
    "            augment=True if split == 'train' else False\n",
    "        )\n",
    "        \n",
    "        dataloaders[split] = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config['training']['batch_size'],\n",
    "            shuffle=True if split == 'train' else False,\n",
    "            num_workers=config['training']['num_workers'],\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "            drop_last=True if split == 'train' else False\n",
    "        )\n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded457f",
   "metadata": {},
   "source": [
    "#   Script di Test\n",
    " \n",
    " Il blocco finale (righe 321-330) permette di testare il preprocessing quando si esegue il file direttamente:\n",
    " \n",
    " 1. Carica la configurazione da `configs/config.yaml`\n",
    " 2. Crea un'istanza di PokemonDataProcessor  \n",
    " 3. Esegue la pipeline completa con `processor.process()`\n",
    " 4. Stampa le statistiche finali\n",
    " \n",
    " Questo è utile per debug e per verificare che tutto funzioni prima di integrare nel training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5d647",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test preprocessing\n",
    "    import yaml\n",
    "    \n",
    "    with open('configs/config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    processor = PokemonDataProcessor(config)\n",
    "    stats = processor.process()\n",
    "    \n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(json.dumps(stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb860d53",
   "metadata": {},
   "source": [
    "#  Riepilogo Parametri Config Utilizzati\n",
    " \n",
    " Il file `preprocessing.py` fa riferimento a questi parametri del file `config.yaml`:\n",
    " \n",
    " **Sezione `data`**:\n",
    " - `raw_data_path`: percorso del file CSV Pokemon\n",
    " - `images_dir`: directory contenente le sprite Pokemon  \n",
    " - `processed_data_path`: directory di output per dati processati\n",
    " - `image_size`: dimensione target per le immagini (320px nel tuo config)\n",
    " - `train_split`, `val_split`, `test_split`: proporzioni degli split\n",
    " \n",
    " **Sezione `model.encoder`**:\n",
    " - `model_name`: nome del tokenizer BERT (\"prajjwal1/bert-mini\")\n",
    " - `max_length`: lunghezza massima sequenze token (128)\n",
    " \n",
    " **Sezione `training`**:\n",
    " - `batch_size`: dimensione batch per DataLoader (2)\n",
    " - `num_workers`: processi paralleli per caricamento dati (1)\n",
    " \n",
    " **Sezione `project`**:\n",
    " - `seed`: seed per riproducibilità (42)\n",
    " \n",
    " Il preprocessing è completamente configurabile attraverso questi parametri, rendendo facile sperimentare con diverse impostazioni.\n",
    "\n",
    "\n",
    "#  Conclusioni\n",
    " \n",
    " Il file `preprocessing.py` implementa una pipeline robusta e completa per preparare i dati Pokemon:\n",
    " \n",
    " 1. **Caricamento intelligente**: Gestisce diversi encoding CSV\n",
    " 2. **Validazione rigorosa**: Controlla sia dati che immagini\n",
    " 3. **Split riproducibili**: Usa seed fisso per risultati consistenti  \n",
    " 4. **Dataset PyTorch pronto**: Integrazione diretta con training loop\n",
    " 5. **Configurazione flessibile**: Tutti i parametri leggibili da config.yaml\n",
    " \n",
    " La struttura modulare permette di:\n",
    " - Eseguire solo parti specifiche della pipeline\n",
    " - Facilmente debug e modificare comportamenti\n",
    " - Riutilizzare componenti in altri progetti\n",
    " \n",
    " Il risultato è un dataset pulito e standardizzato, pronto per alimentare il modello encoder-decoder del progetto PikaPikaGenerator.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
