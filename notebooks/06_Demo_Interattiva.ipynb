{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64a3853",
   "metadata": {},
   "source": [
    "#  PikaPikaGenerator - Interactive Demo\n",
    "# \n",
    "**Progetto:** Generative Synthesis of Pokémon Sprites from Textual Descriptions  \n",
    " **Corso:** Deep Learning - Politecnico di Bari  \n",
    " **Studente:** Pasquale Alessandro Denora  \n",
    " **Professore:** Vito Walter Anelli "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18a364",
   "metadata": {},
   "source": [
    "#  Import e Setup Iniziale\n",
    " \n",
    " Il file inizia importando tutte le librerie necessarie per creare l'interfaccia demo:\n",
    " - **gradio**: Framework per creare interfacce web interattive\n",
    " - **torch**: Per gestire il modello e le operazioni tensori\n",
    " - **PIL**: Per manipolazione immagini generate\n",
    " - **yaml & json**: Per configurazione e serializzazione dati\n",
    " - **pathlib**: Per gestione paths in modo object-oriented\n",
    " - **typing**: Per type hints e migliore documentazione\n",
    " \n",
    " **Import specifici del progetto**:\n",
    " - `src.models.architecture`: Per creare e gestire il modello\n",
    " - `src.utils.visualization`: Per heatmap attention e plot metriche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "from src.models.architecture import create_model\n",
    "from src.utils.visualization import create_attention_heatmap, plot_metrics\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e41e4",
   "metadata": {},
   "source": [
    "#  Classe PikaPikaGeneratorApp - Inizializzazione\n",
    " \n",
    " La classe principale `PikaPikaGeneratorApp` (righe 18-214) gestisce tutta la logica della demo:\n",
    " \n",
    " **Inizializzazione** (righe 21-31):\n",
    " - Carica configurazione da file YAML specificato\n",
    " - Determina device (CPU/GPU) automaticamente\n",
    " - Inizializza attributi per modello e stato caricamento\n",
    " - Chiama `load_model()` per caricare modello addestrato\n",
    " \n",
    " **Attributi principali**:\n",
    " - `self.config`: Configurazione completa del progetto\n",
    " - `self.device`: Device per inferenza (CPU/GPU)\n",
    " - `self.model`: Modello PikaPikaGenerator caricato\n",
    " - `self.model_loaded`: Flag per verificare se modello è pronto\n",
    " \n",
    " **Parametri config utilizzati**: Tutto il file config.yaml viene caricato per consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PikaPikaGeneratorApp:\n",
    "    \"\"\"Classe principale applicazione per l'Interfaccia Gradio di PikaPikaGenerator\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = \"configs/config.yaml\"):\n",
    "        # Carica la configurazione\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = None\n",
    "        self.model_loaded = False\n",
    "        \n",
    "        # Carica il modello\n",
    "        self.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8dd4d8",
   "metadata": {},
   "source": [
    "#  Caricamento del Modello Addestrato\n",
    " \n",
    " Il metodo `load_model()` (righe 33-57) carica il modello addestrato per la demo:\n",
    " \n",
    " **Strategia di caricamento** (righe 35-53):\n",
    " - Cerca prima `best_model.pt` (modello con migliori performance)\n",
    " - Path costruito da `config['paths']['checkpoints_dir']`\n",
    " - Se esiste, procede con caricamento\n",
    " - Se non esiste, imposta `model_loaded = False`\n",
    " \n",
    " **Processo di caricamento** (righe 42-50):\n",
    " - Crea modello usando `create_model(config)`\n",
    " - Carica checkpoint salvato durante training\n",
    " - Restore dei pesi con `load_state_dict()`\n",
    " - Imposta modello in `eval()` mode per inferenza\n",
    " - Aggiorna flag `model_loaded = True`\n",
    " \n",
    " **Error handling robusto** (righe 54-57):\n",
    " - Try/catch per gestire problemi di caricamento\n",
    " - Warning se modello non trovato\n",
    " - Error se caricamento fallisce\n",
    " - Flag sempre aggiornato correttamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4161e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(self):\n",
    "        \"\"\"Carica il modello addestrato\"\"\"\n",
    "        try:\n",
    "            model_path = Path(self.config['paths']['checkpoints_dir']) / 'best_model.pt'\n",
    "            \n",
    "            if model_path.exists():\n",
    "                logger.info(f\"Loading model from {model_path}\")\n",
    "                \n",
    "                # Crea il modello\n",
    "                self.model = create_model(self.config).to(self.device)\n",
    "                \n",
    "                # Carica il checkpoint\n",
    "                checkpoint = torch.load(model_path, map_location=self.device)\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.model.eval()\n",
    "                \n",
    "                self.model_loaded = True\n",
    "                logger.info(\"Model loaded successfully!\")\n",
    "            else:\n",
    "                logger.warning(f\"Model not found at {model_path}\")\n",
    "                self.model_loaded = False\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            self.model_loaded = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08571d99",
   "metadata": {},
   "source": [
    "#  Generazione Singola Sprite con Attention\n",
    " \n",
    " Il metodo `generate_sprite()` (righe 59-95) implementa la generazione singola di sprite:\n",
    " \n",
    " **Input parameters**:\n",
    " - `description`: Testo descrittivo Pokemon\n",
    " - `noise_scale`: Scala del rumore casuale (default 1.0)\n",
    " - `show_attention`: Flag per mostrare attention heatmap\n",
    " \n",
    " **Validazione input** (righe 64-71):\n",
    " - Controlla se modello è caricato correttamente\n",
    " - Verifica che description non sia vuota\n",
    " - Return messaggi di errore user-friendly se problemi\n",
    " \n",
    " **Processo di generazione** (righe 73-87):\n",
    " - Crea rumore casuale con scala specificata\n",
    " - Chiama `model.generate()` per ottenere sprite\n",
    " - Converte tensor output in PIL Image\n",
    " - Opzionalmente genera attention heatmap per interpretabilità\n",
    " \n",
    " **Output triplo**:\n",
    " - `sprite_img`: Immagine Pokemon generata\n",
    " - `attention_img`: Heatmap attention (se richiesta)\n",
    " - `status`: Messaggio di stato per utente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sprite(\n",
    "        self,\n",
    "        description: str,\n",
    "        noise_scale: float = 1.0,\n",
    "        show_attention: bool = False\n",
    "    ) -> Tuple[Image.Image, Optional[Image.Image], str]:\n",
    "        \"\"\"Generate a Pokemon sprite from description\"\"\"\n",
    "        \n",
    "        if not self.model_loaded:\n",
    "            return None, None, \"❌ Model not loaded. Please train the model first.\"\n",
    "        \n",
    "        if not description.strip():\n",
    "            return None, None, \"❌ Please enter a description.\"\n",
    "        \n",
    "        try:\n",
    "            # Genera sprite\n",
    "            noise = torch.randn(1, self.config['model']['generator']['noise_dim']) * noise_scale\n",
    "            noise = noise.to(self.device)\n",
    "            \n",
    "            sprite = self.model.generate(description, noise=noise, device=self.device)\n",
    "            sprite_img = Image.fromarray(sprite)\n",
    "            \n",
    "            # Genera attenzione heatmap se richiesto\n",
    "            attention_img = None\n",
    "            if show_attention:\n",
    "                _, tokens, attention_weights = self.model.get_attention_visualization(\n",
    "                    description, device=self.device\n",
    "                )\n",
    "                attention_img = create_attention_heatmap(tokens, attention_weights)\n",
    "            \n",
    "            status = f\"✅ Generated sprite for: {description[:50]}...\"\n",
    "            \n",
    "            return sprite_img, attention_img, status\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating sprite: {e}\")\n",
    "            return None, None, f\"❌ Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4096f",
   "metadata": {},
   "source": [
    "#  Generazione Batch con Variazioni Multiple\n",
    " \n",
    " Il metodo `batch_generate()` (righe 97-144) permette di generare multiple sprite con variazioni:\n",
    " \n",
    " **Input processing** (righe 102-112):\n",
    " - Parse delle descrizioni (una per linea)\n",
    " - Filtra linee vuote con list comprehension\n",
    " - Verifica che ci sia almeno una descrizione valida\n",
    " - Return early se input non valido\n",
    " \n",
    " **Loop di generazione** (righe 116-124):\n",
    " - Loop nidificato: per ogni descrizione, genera N variazioni\n",
    " - Rumore diverso per ogni variazione (casualità controllata)\n",
    " - Genera sprite chiamando `model.generate()`\n",
    " - Converte ogni output in PIL Image\n",
    " \n",
    " **Annotazione immagini** (righe 127-135):\n",
    " - Usa PIL.ImageDraw per aggiungere testo\n",
    " - Tenta di caricare font arial, fallback a default\n",
    " - Aggiunge nome descrizione + numero variazione\n",
    " - Testo con outline per visibilità su qualsiasi background\n",
    " \n",
    " **Output finale**:\n",
    " - Lista di immagini generate con annotazioni\n",
    " - Status message con count totale di sprite generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d86ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_generate(\n",
    "        self,\n",
    "        descriptions: str,\n",
    "        num_variations: int = 3,\n",
    "        noise_scale: float = 1.0\n",
    "    ) -> Tuple[List[Image.Image], str]:\n",
    "        \"\"\"Genera Sprite Multiple per Descrizioni Multiple\"\"\"\n",
    "        \n",
    "        if not self.model_loaded:\n",
    "            return [], \"❌ Model not loaded.\"\n",
    "        \n",
    "        # Parse descriptions (one per line)\n",
    "        desc_list = [d.strip() for d in descriptions.strip().split('\\n') if d.strip()]\n",
    "        \n",
    "        if not desc_list:\n",
    "            return [], \"❌ Please enter at least one description.\"\n",
    "        \n",
    "        generated_images = []\n",
    "        \n",
    "        try:\n",
    "            for desc in desc_list:\n",
    "                for i in range(num_variations):\n",
    "                    # Rumore differente per ogni variazione\n",
    "                    noise = torch.randn(1, self.config['model']['generator']['noise_dim']) * noise_scale\n",
    "                    noise = noise.to(self.device)\n",
    "                    \n",
    "                    sprite = self.model.generate(desc, noise=noise, device=self.device)\n",
    "                    sprite_img = Image.fromarray(sprite)\n",
    "                    \n",
    "                    # Aggiungi testo alla sprite\n",
    "                    from PIL import ImageDraw, ImageFont\n",
    "                    draw = ImageDraw.Draw(sprite_img)\n",
    "                    try:\n",
    "                        font = ImageFont.truetype(\"arial.ttf\", 10)\n",
    "                    except:\n",
    "                        font = ImageFont.load_default()\n",
    "                    \n",
    "                    text = f\"{desc[:30]}... (v{i+1})\"\n",
    "                    draw.text((5, 5), text, fill='white', font=font, stroke_width=1, stroke_fill='black')\n",
    "                    \n",
    "                    generated_images.append(sprite_img)\n",
    "            \n",
    "            status = f\"✅ Generated {len(generated_images)} sprites from {len(desc_list)} descriptions\"\n",
    "            return generated_images, status\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in batch generation: {e}\")\n",
    "            return [], f\"❌ Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf1e5d",
   "metadata": {},
   "source": [
    "#  Caricamento Metriche di Valutazione\n",
    " \n",
    " Il metodo `load_evaluation_metrics()` (righe 146-176) carica e visualizza le metriche del modello:\n",
    " \n",
    " **Ricerca checkpoint** (righe 149-154):\n",
    " - Scansiona directory checkpoints per trovare file disponibili\n",
    " - Pattern `checkpoint_epoch_*.pt` per tutti i checkpoint\n",
    " - Se nessun checkpoint trovato, return messaggio di errore\n",
    " - Strategia robusta che non assume presenza di file specifici\n",
    " \n",
    " **Selezione ultimo checkpoint** (righe 156-158):\n",
    " - Usa `max()` con `key=lambda` per trovare file più recente\n",
    " - Basato su timestamp di modifica (`stat().st_mtime`)\n",
    " - Carica checkpoint più recente disponibile\n",
    " \n",
    " **Estrazione e visualizzazione metriche** (righe 160-172):\n",
    " - Verifica presenza di `val_metrics` nel checkpoint\n",
    " - Usa `plot_metrics()` da utils.visualization per grafico\n",
    " - Formatta metriche come testo strutturato per display\n",
    " - Return sia immagine che testo per doppia visualizzazione\n",
    " \n",
    " **Error handling**: Try/catch completo per gestire file mancanti o corrotti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813bb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_metrics(self) -> Tuple[Optional[Image.Image], str]:\n",
    "        \"\"\"Load and display evaluation metrics\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Carica metriche dall'ultimo checkpoint\n",
    "            checkpoint_dir = Path(self.config['paths']['checkpoints_dir'])\n",
    "            checkpoint_files = list(checkpoint_dir.glob('checkpoint_epoch_*.pt'))\n",
    "            \n",
    "            if not checkpoint_files:\n",
    "                return None, \"❌ No checkpoints found.\"\n",
    "            \n",
    "            # Ottieni l'ultimo checkpoint\n",
    "            latest_checkpoint = max(checkpoint_files, key=lambda p: p.stat().st_mtime)\n",
    "            checkpoint = torch.load(latest_checkpoint, map_location='cpu')\n",
    "            \n",
    "            if 'val_metrics' in checkpoint:\n",
    "                metrics = checkpoint['val_metrics']\n",
    "                metrics_img = plot_metrics(metrics, f\"Validation Metrics - Epoch {checkpoint['epoch']}\")\n",
    "                \n",
    "                # Formatta le metriche come testo\n",
    "                metrics_text = f\"**Epoch {checkpoint['epoch']} Metrics:**\\n\"\n",
    "                for key, value in metrics.items():\n",
    "                    metrics_text += f\"- {key}: {value:.4f}\\n\"\n",
    "                \n",
    "                return metrics_img, metrics_text\n",
    "            else:\n",
    "                return None, \"❌ No validation metrics found in checkpoint.\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading metrics: {e}\")\n",
    "            return None, f\"❌ Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6c334",
   "metadata": {},
   "source": [
    "##  Informazioni del Modello\n",
    " \n",
    " Il metodo `get_model_info()` (righe 178-214) fornisce informazioni dettagliate sul modello:\n",
    " \n",
    " **Conteggio parametri** (righe 186-187):\n",
    " - `sum(p.numel() for p in model.parameters())`: Conta tutti i parametri\n",
    " - `sum(... if p.requires_grad)`: Conta solo parametri trainable\n",
    " - Informazione cruciale per capire complessità modello\n",
    " \n",
    " **Informazioni architettura** (righe 190-208):\n",
    " - **Text Encoder**: Nome modello BERT e dimensione hidden\n",
    " - **Generator**: Canali base e dimensione output finale\n",
    " - **Training config**: Batch size, learning rate, pesi delle loss\n",
    " - Tutte le info estratte dalla configurazione caricata\n",
    " \n",
    " **Formatting user-friendly** (righe 190-208):\n",
    " - Usa f-strings per formattazione pulita\n",
    " - Numeri formattati con comma separators \n",
    " - Struttura gerarchica con indentazione\n",
    " - Markdown formatting per display ricco in Gradio\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `model.encoder.model_name`, `hidden_dim`, `max_length`\n",
    " - `model.generator.base_channels`, `output_size`  \n",
    " - `training.batch_size`, `learning_rate`\n",
    " - `loss` weights per reconstruction, perceptual, adversarial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ea430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(self) -> str:\n",
    "        \n",
    "        \n",
    "        if not self.model_loaded:\n",
    "            return \"❌ Model not loaded.\"\n",
    "        \n",
    "        try:\n",
    "            # Conta i parametri del modello\n",
    "            total_params = sum(p.numel() for p in self.model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "            \n",
    "            info = f\"\"\"\n",
    "            **Model Architecture:**\n",
    "            - Text Encoder: {self.config['model']['encoder']['model_name']}\n",
    "            - Hidden Dimension: {self.config['model']['encoder']['hidden_dim']}\n",
    "            - Generator Base Channels: {self.config['model']['generator']['base_channels']}\n",
    "            - Output Size: {self.config['model']['generator']['output_size']}x{self.config['model']['generator']['output_size']}\n",
    "            \n",
    "            **Parameters:**\n",
    "            - Total: {total_params:,}\n",
    "            - Trainable: {trainable_params:,}\n",
    "            \n",
    "            **Training Configuration:**\n",
    "            - Batch Size: {self.config['training']['batch_size']}\n",
    "            - Learning Rate: {self.config['training']['learning_rate']}\n",
    "            - Loss Weights:\n",
    "              - Reconstruction: {self.config['loss']['reconstruction_weight']}\n",
    "              - Perceptual: {self.config['loss']['perceptual_weight']}\n",
    "              - Adversarial: {self.config['loss']['adversarial_weight']}\n",
    "            \n",
    "            **Device:** {self.device}\n",
    "            \"\"\"\n",
    "            \n",
    "            return info\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"❌ Error getting model info: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81ecf4",
   "metadata": {},
   "source": [
    "#  Creazione Interfaccia Gradio - Setup Principale\n",
    "\n",
    " La funzione `create_interface()` (righe 217-378) crea l'interfaccia web completa:\n",
    " \n",
    " **Inizializzazione app** (righe 220-234):\n",
    " - Istanzia `PikaPikaGeneratorApp()` che carica tutto\n",
    " - Setup CSS customizzato per styling avanzato\n",
    " - Definisce stili per header banner e layout generale\n",
    " \n",
    " **CSS Styling** (righe 224-234):\n",
    " - Font family professionale: Segoe UI, Tahoma, Geneva\n",
    " - Header banner con gradient background (purple to blue)\n",
    " - Padding, border-radius per estetica moderna\n",
    " - Text alignment e colors coordinate\n",
    " \n",
    " **Gradio Blocks setup** (righe 237-248):\n",
    " - `gr.Blocks()` per layout customizzato avanzato\n",
    " - CSS applicato e title impostato\n",
    " - Header HTML con branding del progetto\n",
    " - Subtitle che spiega functionality e tecnologie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3989c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interface():\n",
    "    \"\"\"Crea l'interfaccia Gradio\"\"\"\n",
    "    \n",
    "    app = PikaPikaGeneratorApp()\n",
    "    \n",
    "    # Stile CSS per l'interfaccia\n",
    "    css = \"\"\"\n",
    "    .gradio-container {\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    .header-banner {\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        padding: 2rem;\n",
    "        border-radius: 1rem;\n",
    "        text-align: center;\n",
    "        color: white;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=css, title=\"PikaPikaGenerator - Advanced Pokemon Sprite Generation\") as demo:\n",
    "        \n",
    "        # Header\n",
    "        gr.HTML(\"\"\"\n",
    "        <div class=\"header-banner\">\n",
    "            <h1> PikaPikaGenerator </h1>\n",
    "            <h3>Advanced Text-to-Pokemon Sprite Generation</h3>\n",
    "            <p>Using Encoder-Decoder Architecture with Attention Mechanism</p>\n",
    "        </div>\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9e889",
   "metadata": {},
   "source": [
    "#  Tab \"Generate Sprite\" - Generazione Singola\n",
    " \n",
    " **Primo tab principale** (righe 248-275): Interface per generazione singola sprite\n",
    " \n",
    " **Layout a colonne** (righe 251-275):\n",
    " - **Colonna sinistra (scale=2)**: Input controls più larghi\n",
    "   - `gr.Textbox()` per descrizione Pokemon (3 linee)\n",
    "   - `gr.Slider()` per noise scale (0.1-2.0, default 1.0)\n",
    "   - `gr.Checkbox()` per abilitare attention heatmap\n",
    "   - `gr.Button()` principale per generazione\n",
    " \n",
    " - **Colonna destra (scale=1)**: Output display\n",
    "   - `gr.Image()` per sprite generata\n",
    "   - `gr.Image()` per attention heatmap (hidden di default)\n",
    "   - `gr.Textbox()` per status messages\n",
    " \n",
    " **Esempi predefiniti** (righe 278-291):\n",
    " - 8 descrizioni Pokemon diverse per testing rapido\n",
    " - Coprono diversi tipi: electric, water, fire, grass, ghost, fairy, steel, ice\n",
    " - Pattern realistico che utenti potrebbero usare\n",
    " - `gr.Examples()` collega examples all'input textbox\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136470d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Tabs():\n",
    "            \n",
    "            # Single Generation Tab\n",
    "            with gr.TabItem(\" Generate Sprite\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        description_input = gr.Textbox(\n",
    "                            label=\"Pokemon Description\",\n",
    "                            placeholder=\"Enter a detailed Pokemon description...\",\n",
    "                            lines=3\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            noise_scale = gr.Slider(\n",
    "                                minimum=0.1, maximum=2.0, value=1.0, step=0.1,\n",
    "                                label=\"Noise Scale (Variation)\"\n",
    "                            )\n",
    "                            show_attention = gr.Checkbox(\n",
    "                                label=\"Show Attention Heatmap\",\n",
    "                                value=False\n",
    "                            )\n",
    "                        \n",
    "                        generate_btn = gr.Button(\" Generate Sprite\", variant=\"primary\", size=\"lg\")\n",
    "                    \n",
    "                    with gr.Column(scale=1):\n",
    "                        generated_image = gr.Image(label=\"Generated Sprite\", type=\"pil\")\n",
    "                        attention_heatmap = gr.Image(label=\"Attention Heatmap\", type=\"pil\", visible=False)\n",
    "                        status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                \n",
    "                # Esempi\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        [\"A small yellow electric mouse Pokemon with red cheeks and a lightning bolt shaped tail\"],\n",
    "                        [\"A large blue turtle Pokemon with water cannons protruding from its shell\"],\n",
    "                        [\"An orange dragon-type Pokemon with wings and a flame on its tail\"],\n",
    "                        [\"A pink fairy Pokemon with ribbons and a sweet expression\"],\n",
    "                        [\"A dark ghost Pokemon with purple flames and menacing red eyes\"],\n",
    "                        [\"A steel-type bird Pokemon with sharp metallic feathers\"],\n",
    "                        [\"A grass Pokemon that looks like a walking tree with leaves for hands\"],\n",
    "                        [\"An ice-type Pokemon resembling a crystalline wolf with frozen breath\"]\n",
    "                    ],\n",
    "                    inputs=[description_input],\n",
    "                    label=\"Example Descriptions:\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb93f55",
   "metadata": {},
   "source": [
    "# Tab \"Batch Generation\" - Generazione Multiple\n",
    " \n",
    " **Secondo tab principale** (righe 294-323): Interface per generazione batch\n",
    " \n",
    " **Input area** (righe 296-313):\n",
    " - `gr.Textbox()` con 8 linee per multiple descriptions\n",
    " - Placeholder che spiega formato \"one per line\"\n",
    " - `gr.Slider()` per numero variazioni per descrizione (1-5)\n",
    " - `gr.Slider()` per noise scale globale\n",
    " - `gr.Button()` per avviare batch generation\n",
    " \n",
    " **Output area** (righe 315-323):\n",
    " - `gr.Gallery()` per mostrare tutte le immagini generate\n",
    " - `show_label=True` per chiarezza\n",
    " - Layout griglia: 4 colonne, 2 righe\n",
    " - `height=\"auto\"` per scrolling se necessario\n",
    " - `gr.Textbox()` per status batch operation\n",
    " \n",
    " **Vantaggi batch mode**:\n",
    " - Genera multiple Pokemon simultaneamente\n",
    " - Variazioni multiple per ogni descrizione\n",
    " - Efficient per testing o confronti\n",
    " - Gallery view per vedere tutto insieme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generation Tab\n",
    "with gr.TabItem(\" Batch Generation\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        batch_descriptions = gr.Textbox(\n",
    "                            label=\"Pokemon Descriptions (one per line)\",\n",
    "                            placeholder=\"Enter multiple descriptions, one per line...\",\n",
    "                            lines=8\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            num_variations = gr.Slider(\n",
    "                                minimum=1, maximum=5, value=3, step=1,\n",
    "                                label=\"Variations per Description\"\n",
    "                            )\n",
    "                            batch_noise_scale = gr.Slider(\n",
    "                                minimum=0.1, maximum=2.0, value=1.0, step=0.1,\n",
    "                                label=\"Noise Scale\"\n",
    "                            )\n",
    "                        \n",
    "                        batch_generate_btn = gr.Button(\" Generate Batch\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        batch_gallery = gr.Gallery(\n",
    "                            label=\"Generated Sprites\",\n",
    "                            show_label=True,\n",
    "                            columns=4,\n",
    "                            rows=2,\n",
    "                            height=\"auto\"\n",
    "                        )\n",
    "                        batch_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4972f",
   "metadata": {},
   "source": [
    "#  Tab \"Model Info & Metrics\" - Informazioni e Metriche\n",
    " \n",
    " **Terzo tab principale** (righe 326-335): Interface per info modello e metriche\n",
    " \n",
    " **Layout a due colonne**:\n",
    " \n",
    " **Colonna sinistra** (righe 328-331):\n",
    " - `gr.Button()` per caricare metriche di valutazione\n",
    " - `gr.Image()` per visualizzare plot delle metriche\n",
    " - `gr.Markdown()` per testo formattato delle metriche\n",
    " \n",
    " **Colonna destra** (righe 333-335):\n",
    " - `gr.Button()` per ottenere info del modello\n",
    " - `gr.Markdown()` per display info architettura\n",
    " \n",
    " **Funzionalità**:\n",
    " - **Load Metrics**: Carica ultimo checkpoint e mostra performance\n",
    " - **Model Info**: Mostra architettura, parametri, configurazione training\n",
    " - **Visual + Text**: Doppia rappresentazione per completeness\n",
    " - **Markdown support**: Rich formatting per info strutturate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec96ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Info Tab\n",
    "with gr.TabItem(\" Model Info & Metrics\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        info_btn = gr.Button(\" Load Evaluation Metrics\", variant=\"primary\")\n",
    "                        metrics_plot = gr.Image(label=\"Metrics Visualization\", type=\"pil\")\n",
    "                        metrics_text = gr.Markdown()\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        model_info_btn = gr.Button(\" Get Model Info\", variant=\"primary\")\n",
    "                        model_info_display = gr.Markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3daa5ae",
   "metadata": {},
   "source": [
    "#  Event Handlers e Interazioni\n",
    " \n",
    " **Footer HTML** (righe 338-343): Footer informativo del progetto\n",
    " \n",
    " **Event handlers setup** (righe 346-377): Connessioni tra UI e funzioni backend\n",
    " \n",
    " **Dynamic visibility** (righe 346-347):\n",
    " - Funzione `update_attention_visibility()` per show/hide attention heatmap\n",
    " - Collegata al checkbox `show_attention`\n",
    " - Return `gr.update(visible=show)` per controllo dinamico UI\n",
    " \n",
    " **Main button connections**:\n",
    " - **Generate button**: Collega a `app.generate_sprite()` con 3 input → 3 output\n",
    " - **Batch button**: Collega a `app.batch_generate()` con 3 input → 2 output\n",
    " - **Metrics button**: Collega a `app.load_evaluation_metrics()` → 2 output\n",
    " - **Info button**: Collega a `app.get_model_info()` → 1 output\n",
    " \n",
    " **Return demo object**: Interfaccia completa pronta per lancio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # Event handlers\n",
    "        def update_attention_visibility(show):\n",
    "            return gr.update(visible=show)\n",
    "        \n",
    "        show_attention.change(\n",
    "            fn=update_attention_visibility,\n",
    "            inputs=[show_attention],\n",
    "            outputs=[attention_heatmap]\n",
    "        )\n",
    "        \n",
    "        generate_btn.click(\n",
    "            fn=app.generate_sprite,\n",
    "            inputs=[description_input, noise_scale, show_attention],\n",
    "            outputs=[generated_image, attention_heatmap, status_output]\n",
    "        )\n",
    "        \n",
    "        batch_generate_btn.click(\n",
    "            fn=app.batch_generate,\n",
    "            inputs=[batch_descriptions, num_variations, batch_noise_scale],\n",
    "            outputs=[batch_gallery, batch_status]\n",
    "        )\n",
    "        \n",
    "        info_btn.click(\n",
    "            fn=app.load_evaluation_metrics,\n",
    "            outputs=[metrics_plot, metrics_text]\n",
    "        )\n",
    "        \n",
    "        model_info_btn.click(\n",
    "            fn=app.get_model_info,\n",
    "            outputs=[model_info_display]\n",
    "        )\n",
    "    \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a90a3",
   "metadata": {},
   "source": [
    "# Funzione Main - Lancio della Demo\n",
    " \n",
    " La funzione `main()` (righe 380-395) avvia effettivamente la demo Gradio:\n",
    " \n",
    " **Setup finale** (righe 382-384):\n",
    " - Log message per indicare startup\n",
    " - Chiama `create_interface()` per ottenere demo object\n",
    " - Tutto è pronto per il lancio\n",
    " \n",
    " **Configurazione lancio** (righe 386-391):\n",
    " - `server_name=\"0.0.0.0\"`: Accessibile da qualsiasi IP (non solo localhost)\n",
    " - `server_port=7860`: Porta standard per demo Gradio\n",
    " - `share=False`: Non crea tunnel pubblico (locale only)\n",
    " - `show_error=True`: Mostra errori completi per debug\n",
    " \n",
    " **Entry point** (righe 394-395):\n",
    " - `if __name__ == \"__main__\"`: Permette esecuzione diretta file\n",
    " - Chiama `main()` per avviare demo standalone\n",
    " \n",
    " **Utilizzo**: `python app.py` per lanciare demo indipendentemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f781376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Avvia l'app Gradio\"\"\"\n",
    "    logger.info(\"Starting PikaPikaGenerator Gradio App...\")\n",
    "    \n",
    "    demo = create_interface()\n",
    "    \n",
    "    demo.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        share=False,\n",
    "        show_error=True\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9a861",
   "metadata": {},
   "source": [
    "#  Riepilogo Parametri Config Utilizzati\n",
    " \n",
    " Il file `app.py` utilizza questi parametri dal file `config.yaml`:\n",
    " \n",
    " **Sezione `paths`**:\n",
    " - `checkpoints_dir`: Directory dei modelli salvati (\"data/models/checkpoints_hq_v2\")\n",
    " - Utilizzato per caricare `best_model.pt` e checkpoint per metriche\n",
    "\n",
    " **Sezione `model.generator`**:\n",
    " - `noise_dim`: Dimensione vettore rumore (256)\n",
    " - `base_channels`: Canali base generatore (768)\n",
    " - `output_size`: Dimensione finale sprite (320x320)\n",
    " - Utilizzati per info modello e generazione\n",
    "\n",
    " **Sezione `model.encoder`**:\n",
    " - `model_name`: Nome tokenizer BERT (\"prajjwal1/bert-mini\")\n",
    " - `hidden_dim`: Dimensione features testuali (512)\n",
    " - `max_length`: Lunghezza massima sequenze (128)\n",
    " - Utilizzati per info architettura\n",
    " \n",
    " **Sezione `training`**:\n",
    " - `batch_size`: Dimensione batch (2)\n",
    " - `learning_rate`: Learning rate (0.0001)\n",
    " - Utilizzati per display configurazione training\n",
    " \n",
    " **Sezione `loss`**:\n",
    " - `reconstruction_weight`: Peso L1 loss (15.0)\n",
    " - `perceptual_weight`: Peso LPIPS loss (2.5)\n",
    " - `adversarial_weight`: Peso adversarial loss (0.5)\n",
    " - Utilizzati per info training configuration\n",
    " \n",
    "#  Conclusioni - Demo Interattiva PikaPikaGenerator\n",
    " \n",
    " Il file `app.py` implementa una demo Gradio completa e professionale:\n",
    " \n",
    "  **Caratteristiche Principali**:\n",
    " 1. **Interfaccia Multi-Tab**: Organizzazione logica delle funzionalità\n",
    " 2. **Single Generation**: Generazione sprite con attention visualization\n",
    " 3. **Batch Generation**: Multiple sprite con variazioni controllate\n",
    " 4. **Model Analytics**: Info architettura e metriche performance\n",
    " 5. **Professional UI**: CSS custom, esempi predefiniti, styling moderno\n",
    " \n",
    "  **Funzionalità Avanzate**:\n",
    " - **Attention Heatmap**: Visualizzazione interpretabilità modello\n",
    " - **Noise Scale Control**: Controllo variabilità generazione\n",
    " - **Batch Processing**: Efficient generation di multiple sprite\n",
    " - **Metrics Visualization**: Monitoraggio performance modello\n",
    " - **Error Handling**: Gestione robusta di tutti gli edge case\n",
    " \n",
    "  **User Experience**:\n",
    " - **Esempi predefiniti**: 8 descrizioni Pokemon ready-to-use\n",
    " - **Real-time feedback**: Status messages per ogni operazione\n",
    " - **Gallery view**: Visualizzazione organizzata per batch results\n",
    " - **Responsive design**: Layout adattivo per diverse screen size\n",
    " - **Rich formatting**: Markdown support per info strutturate\n",
    "\n",
    "  **Integration nel Progetto**:\n",
    " - **Config consistency**: Stessa configurazione del training\n",
    " - **Model compatibility**: Carica checkpoint salvati dal trainer\n",
    " - **Utils integration**: Usa funzioni visualization per plots\n",
    " - **Standalone operation**: Può essere lanciata indipendentemente\n",
    " \n",
    "  **Aspetti Tecnici**:\n",
    "- **Memory efficient**: Proper device management e cleanup\n",
    "- **Error resilient**: Fallback graceful per problemi modello\n",
    "- **Configurable**: Tutti i parametri leggibili da config.yaml\n",
    "- **Production ready**: Logging appropriato e error handling\n",
    "\n",
    " La demo PikaPikaGenerator offre un'**esperienza utente completa** per interagire con il modello addestrato, perfetta per showcase, testing e valutazione qualitativa! \n",
    " \n",
    "#  **Requisiti per Esecuzione**:\n",
    " - Modello addestrato salvato come `best_model.pt`\n",
    " - Configurazione `config.yaml` con parametri corretti\n",
    " - Gradio installato (`pip install gradio`)\n",
    " - Esecuzione: `python app.py` → Demo disponibile su http://localhost:7860"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
