{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8517f41",
   "metadata": {},
   "source": [
    "#  PikaPikaGenerator - Training Model \n",
    "# \n",
    "**Progetto:** Generative Synthesis of Pokémon Sprites from Textual Descriptions  \n",
    " **Corso:** Deep Learning - Politecnico di Bari  \n",
    " **Studente:** Pasquale Alessandro Denora  \n",
    " **Professore:** Vito Walter Anelli "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d4bc1",
   "metadata": {},
   "source": [
    "#  Import e Setup Iniziale\n",
    " \n",
    " Il file inizia importando tutte le librerie necessarie per il training del modello:\n",
    " - **torch & torch.optim**: Framework PyTorch e ottimizzatori\n",
    " - **torch.cuda.amp**: Automatic Mixed Precision per training accelerato\n",
    " - **torch.utils.tensorboard**: Logging e visualizzazione metriche\n",
    " - **tqdm**: Progress bar per monitoraggio training\n",
    " - **wandb**: Weights & Biases per experiment tracking avanzato\n",
    " - **PIL**: Per salvare immagini generate durante il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Optional, Tuple\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "from PIL import Image\n",
    "\n",
    "from src.models.architecture import create_model, Discriminator\n",
    "from src.data.preprocessing import create_dataloaders\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc59b8",
   "metadata": {},
   "source": [
    "#  Classe Trainer - Inizializzazione\n",
    " \n",
    " La classe `Trainer` (righe 27-627) gestisce tutto il processo di training. Nel costruttore vengono inizializzati:\n",
    " \n",
    " **Setup del dispositivo** (riga 31): Seleziona automaticamente GPU se disponibile, altrimenti CPU\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['project']['device']`: dispositivo preferito\n",
    " - `config['loss']['adversarial_weight']`: peso per training adversarial\n",
    " \n",
    " **Componenti inizializzati**:\n",
    " - Modello principale (generatore)\n",
    " - Discriminatore (se training adversarial abilitato)\n",
    " - Ottimizzatori e scheduler\n",
    " - Loss functions\n",
    " - Sistema di logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config['project']['device'] if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Crea cartelle necessarie\n",
    "        self.setup_directories()\n",
    "        \n",
    "        # Inizializza il modello\n",
    "        self.model = create_model(config).to(self.device)\n",
    "        \n",
    "        # Inizializza il discriminatore per l'addestramento avversariale\n",
    "        self.use_adversarial = config['loss']['adversarial_weight'] > 0\n",
    "        if self.use_adversarial:\n",
    "            self.discriminator = Discriminator(config).to(self.device)\n",
    "        \n",
    "        # Inizializza l'ottimizzatore\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Inizializza la loss functions\n",
    "        self.setup_losses()\n",
    "        \n",
    "        \n",
    "        self.scaler = GradScaler() if self.device.type == 'cuda' else None\n",
    "        \n",
    "        # Logging\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # Traccio il miglior modello\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821e948",
   "metadata": {},
   "source": [
    "#  Setup Directory e Gestione File\n",
    " \n",
    " Il metodo `setup_directories()` (righe 60-67) crea automaticamente tutte le cartelle necessarie per il training:\n",
    " \n",
    " **Directory create**:\n",
    " - `checkpoints_dir`: Per salvare i modelli durante il training\n",
    " - `samples_dir`: Per salvare esempi di immagini generate\n",
    " - `logs_dir`: Per i log di TensorBoard\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['paths']['checkpoints_dir']`: path checkpoints (es: \"data/models/checkpoints_hq_v2\")\n",
    " - `config['paths']['samples_dir']`: path samples (es: \"outputs/samples_hq_v2\")  \n",
    " - `config['paths']['logs_dir']`: path logs (es: \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca20d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories(self):\n",
    "    \"\"\"Creo le cartelle necessarie\"\"\"\n",
    "    self.checkpoint_dir = Path(self.config['paths']['checkpoints_dir'])\n",
    "    self.samples_dir = Path(self.config['paths']['samples_dir'])\n",
    "    self.logs_dir = Path(self.config['paths']['logs_dir'])\n",
    "    \n",
    "    for dir_path in [self.checkpoint_dir, self.samples_dir, self.logs_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbca339",
   "metadata": {},
   "source": [
    "#  Setup Ottimizzatori e Scheduler\n",
    " \n",
    " Il metodo `setup_optimizers()` (righe 69-94) configura gli ottimizzatori per generatore e discriminatore:\n",
    " \n",
    " **Ottimizzatore Generatore** (righe 72-76):\n",
    " - Usa Adam optimizer su tutti i parametri del modello\n",
    " - Learning rate e beta parameters da config\n",
    " \n",
    " **Ottimizzatore Discriminatore** (righe 79-84):\n",
    " - Solo se training adversarial abilitato\n",
    " - Learning rate 2x rispetto al generatore (comune pratica GAN)\n",
    " \n",
    " **Scheduler Learning Rate** (righe 87-94):\n",
    " - ReduceLROnPlateau: riduce LR quando validation loss smette di migliorare\n",
    " - Pazienza di 5 epoche, riduzione factor 0.5\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['training']['learning_rate']`: learning rate base (0.0001)\n",
    " - `config['training']['beta1']`, `config['training']['beta2']`: parametri Adam (0.0, 0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_optimizers(self):\n",
    "    \"\"\"Setto gli ottimizzatori e gli scheduler\"\"\"\n",
    "    # Genera gli ottimizzatori\n",
    "    self.optimizer_g = optim.Adam(\n",
    "        self.model.parameters(),\n",
    "        lr=self.config['training']['learning_rate'],\n",
    "        betas=(self.config['training']['beta1'], self.config['training']['beta2'])\n",
    "    )\n",
    "    \n",
    "    # Ottimizzatore per il discriminatore se usato\n",
    "    if self.use_adversarial:\n",
    "        self.optimizer_d = optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=self.config['training']['learning_rate'] * 2, \n",
    "            betas=(self.config['training']['beta1'], self.config['training']['beta2'])\n",
    "        )\n",
    "    \n",
    "    # Schedulatore learning rate\n",
    "    self.scheduler_g = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        self.optimizer_g, mode='min', patience=5, factor=0.5\n",
    "    )\n",
    "    \n",
    "    if self.use_adversarial:\n",
    "        self.scheduler_d = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer_d, mode='min', patience=5, factor=0.5\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee66a81",
   "metadata": {},
   "source": [
    "#  Setup Loss Functions\n",
    " \n",
    " Il metodo `setup_losses()` (righe 96-113) inizializza tutte le loss function utilizzate:\n",
    " \n",
    " **L1 Loss** (riga 99): Loss di ricostruzione pixel-wise, preferita rispetto a L2 per immagini meno sfocate\n",
    " \n",
    " **Perceptual Loss LPIPS** (righe 102-109): \n",
    " - Misura similarità semantica usando deep features\n",
    " - Più importante della semplice similarità pixel-wise\n",
    " - Gestisce ImportError se libreria LPIPS non disponibile\n",
    " \n",
    " **Adversarial Loss** (righe 112-113):\n",
    " - BCEWithLogitsLoss per classificazione real/fake\n",
    " - Solo se training adversarial abilitato\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['loss']['perceptual_weight']`: peso loss perceptuale (2.5)\n",
    " - `config['loss']['adversarial_weight']`: peso loss adversarial (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_losses(self):\n",
    "    \"\"\"Setto la  loss functions\"\"\"\n",
    "    # Ricostruzione L1 loss\n",
    "    self.l1_loss = nn.L1Loss()\n",
    "    \n",
    "    # Loss perceptuale (LPIPS)\n",
    "    if self.config['loss']['perceptual_weight'] > 0:\n",
    "        try:\n",
    "            import lpips\n",
    "            self.perceptual_loss = lpips.LPIPS(net='alex').to(self.device)\n",
    "            logger.info(\"LPIPS perceptual loss initialized\")\n",
    "        except ImportError:\n",
    "            logger.warning(\"LPIPS not available, disabling perceptual loss\")\n",
    "            self.config['loss']['perceptual_weight'] = 0\n",
    "    \n",
    "    # Loss avversariale\n",
    "    if self.use_adversarial:\n",
    "        self.adversarial_loss = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b0f56",
   "metadata": {},
   "source": [
    "#  Setup Logging - TensorBoard e Weights & Biases\n",
    " \n",
    " Il metodo `setup_logging()` (righe 115-133) configura i sistemi di logging per monitorare il training:\n",
    " \n",
    " **TensorBoard** (righe 118-119):\n",
    " - Crea SummaryWriter con timestamp per log unici\n",
    " - Salva nella directory logs con nome run_YYYYMMDD_HHMMSS\n",
    " \n",
    " **Weights & Biases** (righe 122-133):\n",
    " - Sistema avanzato per experiment tracking e comparison\n",
    " - Include model watching per tracking automatico gradients\n",
    " - Gestisce errori di connessione gracefully\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['logging']['use_wandb']`: abilita W&B (false nel tuo config)\n",
    " - `config['logging']['project_name']`: nome progetto W&B (\"pikapika-high-quality-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733cee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(self):\n",
    "    \"\"\"Setto il logging e TensorBoard\"\"\"\n",
    "    # TensorBoard\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    self.writer = SummaryWriter(self.logs_dir / f'run_{timestamp}')\n",
    "    \n",
    "    # Weights & Biases\n",
    "    if self.config['logging'].get('use_wandb', False):\n",
    "        try:\n",
    "            wandb.init(\n",
    "                project=self.config['logging']['project_name'],\n",
    "                config=self.config,\n",
    "                name=f\"run_{timestamp}\"\n",
    "            )\n",
    "            wandb.watch(self.model)\n",
    "            logger.info(\"W&B logging initialized\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to initialize W&B: {e}\")\n",
    "            self.config['logging']['use_wandb'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca7233",
   "metadata": {},
   "source": [
    "#  Calcolo Metriche di Valutazione\n",
    " \n",
    " Il metodo `compute_metrics()` (righe 135-257) calcola metriche comprehensive per valutare la qualità delle immagini generate:\n",
    " \n",
    " **Metriche implementate**:\n",
    " 1. **SSIM** (righe 149-173): Structural Similarity Index, misura similarità strutturale\n",
    " 2. **PSNR** (righe 175-188): Peak Signal-to-Noise Ratio, qualità di ricostruzione  \n",
    " 3. **LPIPS** (righe 190-202): Learned Perceptual Image Patch Similarity\n",
    " 4. **FID approssimato** (righe 205-225): Fréchet Inception Distance semplificato\n",
    " 5. **IS approssimato** (righe 227-237): Inception Score semplificato\n",
    " \n",
    " **Robustezza**: Ogni metrica ha error handling completo per evitare crash durante training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d68926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(self, real_images: torch.Tensor, fake_images: torch.Tensor) -> Dict[str, float]:\n",
    "    \"\"\"Compute evaluation metrics with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        metrics = {}\n",
    "        \n",
    "        # Ensure images are in valid range\n",
    "        real_images = torch.clamp(real_images, -1, 1)\n",
    "        fake_images = torch.clamp(fake_images, -1, 1)\n",
    "        \n",
    "        # Convert to numpy for some metrics\n",
    "        real_np = real_images.detach().cpu().numpy()\n",
    "        fake_np = fake_images.detach().cpu().numpy()\n",
    "        \n",
    "        # SSIM\n",
    "        try:\n",
    "            from skimage.metrics import structural_similarity as ssim\n",
    "            ssim_scores = []\n",
    "            for i in range(min(real_np.shape[0], 8)):  # Limita a 8 immagini per efficienza\n",
    "                # Converti da [-1,1] a [0,1] e trasponi HWC\n",
    "                real_img = np.transpose((real_np[i] + 1) / 2, (1, 2, 0))\n",
    "                fake_img = np.transpose((fake_np[i] + 1) / 2, (1, 2, 0))\n",
    "                \n",
    "                # Converti a scala di grigi\n",
    "                real_gray = np.mean(real_img, axis=2)\n",
    "                fake_gray = np.mean(fake_img, axis=2)\n",
    "                \n",
    "                # Clippa i valori per evitare errori\n",
    "                real_gray = np.clip(real_gray, 0, 1)\n",
    "                fake_gray = np.clip(fake_gray, 0, 1)\n",
    "                \n",
    "                score = ssim(real_gray, fake_gray, data_range=1.0)\n",
    "                if not np.isnan(score) and not np.isinf(score):\n",
    "                    ssim_scores.append(score)\n",
    "            \n",
    "            metrics['ssim'] = float(np.mean(ssim_scores)) if ssim_scores else 0.5\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"SSIM calculation failed: {e}\")\n",
    "            metrics['ssim'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452028e8",
   "metadata": {},
   "source": [
    "#  Training Step - Cuore del Training\n",
    " \n",
    " Il metodo `train_step()` (righe 259-359) implementa un singolo step di training:\n",
    " \n",
    " **Flusso di training**:\n",
    " 1. **Move batch to device** (righe 263-268): Sposta dati su GPU/CPU\n",
    " 2. **Train Discriminatore** (righe 271-301): Se adversarial training abilitato\n",
    "    - Genera fake images con generatore\n",
    "    - Classifica real vs fake images  \n",
    "    - Calcola adversarial loss per discriminatore\n",
    " 3. **Train Generatore** (righe 304-332): Training principale\n",
    "    - Calcola reconstruction loss (L1)\n",
    "    - Calcola perceptual loss (LPIPS) se abilitata\n",
    "    - Calcola adversarial loss per fooling discriminatore\n",
    " 4. **Backpropagation** (righe 335-340): Con gradient clipping e AMP support\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['loss']['reconstruction_weight']`: peso L1 loss (15.0)\n",
    " - `config['loss']['perceptual_weight']`: peso LPIPS loss (2.5)\n",
    " - `config['loss']['adversarial_weight']`: peso adversarial loss (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(self, batch: Dict) -> Dict[str, float]:\n",
    "    \"\"\"Single training step\"\"\"\n",
    "    try:\n",
    "        # Move batch to device\n",
    "        images = batch['image'].to(self.device)\n",
    "        input_ids = batch['input_ids'].to(self.device)\n",
    "        attention_mask = batch['attention_mask'].to(self.device)\n",
    "        \n",
    "        batch_size = images.shape[0]\n",
    "        losses = {}\n",
    "        \n",
    "        # Train discriminator (if using adversarial training)\n",
    "        if self.use_adversarial:\n",
    "            self.optimizer_d.zero_grad()\n",
    "            \n",
    "            with autocast(enabled=self.scaler is not None):\n",
    "                # Genera immagini fake\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(input_ids, attention_mask)\n",
    "                    fake_images = outputs['generated_image']\n",
    "                \n",
    "                # Predizioni del discriminatore\n",
    "                real_pred = self.discriminator(images)\n",
    "                fake_pred = self.discriminator(fake_images.detach())\n",
    "                \n",
    "                # Labels\n",
    "                real_labels = torch.ones_like(real_pred)\n",
    "                fake_labels = torch.zeros_like(fake_pred)\n",
    "                \n",
    "                # Loss di discriminatore\n",
    "                d_loss_real = self.adversarial_loss(real_pred, real_labels)\n",
    "                d_loss_fake = self.adversarial_loss(fake_pred, fake_labels)\n",
    "                d_loss = (d_loss_real + d_loss_fake) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797fd46",
   "metadata": {},
   "source": [
    "#  Validazione del Modello\n",
    " \n",
    " Il metodo `validate()` (righe 361-442) esegue la validazione del modello su validation set:\n",
    " \n",
    " **Processo di validazione**:\n",
    " 1. **Model eval mode** (riga 363): Disabilita dropout e batch norm training\n",
    " 2. **No gradient computation** (riga 368): Risparmia memoria e accelera validazione  \n",
    " 3. **Loop sui batch** (righe 369-381): Calcola loss e metriche su ogni batch\n",
    " 4. **Calcolo metriche** (righe 383-387): Solo sui primi 3 batch per efficienza\n",
    " 5. **Aggregazione risultati** (righe 398-427): Media delle loss e metriche\n",
    " \n",
    " **Robustezza**:\n",
    " - Error handling per ogni batch per evitare crash\n",
    " - Valori di default se computation fallisce\n",
    " - Validation di tutti i valori per evitare NaN/Inf\n",
    " \n",
    " **Output**: Dizionario con val_loss e tutte le metriche (SSIM, PSNR, FID, IS, LPIPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f794b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(self, val_loader) -> Dict[str, float]:\n",
    "        \"\"\"Validation loop with robust error handling\"\"\"\n",
    "        self.model.eval()\n",
    "        val_losses = []\n",
    "        val_metrics = []\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"Validating\")):\n",
    "                    try:\n",
    "                        images = batch['image'].to(self.device)\n",
    "                        input_ids = batch['input_ids'].to(self.device)\n",
    "                        attention_mask = batch['attention_mask'].to(self.device)\n",
    "                        \n",
    "                        # Genera immagini\n",
    "                        outputs = self.model(input_ids, attention_mask)\n",
    "                        generated_images = outputs['generated_image']\n",
    "                        \n",
    "                        # Calcola le loss\n",
    "                        recon_loss = self.l1_loss(generated_images, images)\n",
    "                        val_losses.append(float(recon_loss.item()))\n",
    "                        \n",
    "                        # Calcola le metriche\n",
    "                        if batch_idx < 3:  # Calcola le metriche solo per i primi 3 batch\n",
    "                            metrics = self.compute_metrics(generated_images, images)\n",
    "                            if metrics is not None:\n",
    "                                val_metrics.append(metrics)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Error in validation batch {batch_idx}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # Gestisce i casi in cui non sono state calcolate metriche valide\n",
    "            if not val_losses:\n",
    "                logger.warning(\"No valid losses computed during validation\")\n",
    "                return {'val_loss': 1.0, 'ssim': 0.5, 'psnr': 20.0, 'fid': 50.0, 'is_score': 2.0, 'lpips': 0.5}\n",
    "            \n",
    "            # Calcola la loss media\n",
    "            avg_loss = float(np.mean(val_losses))\n",
    "            \n",
    "            # Calcola le metriche medie\n",
    "            if val_metrics:\n",
    "                # Filtra i None values\n",
    "                valid_metrics = [m for m in val_metrics if m is not None and isinstance(m, dict)]\n",
    "                \n",
    "                if valid_metrics:\n",
    "                    avg_metrics = {}\n",
    "                    for key in valid_metrics[0].keys():\n",
    "                        values = []\n",
    "                        for m in valid_metrics:\n",
    "                            if key in m and np.isfinite(m[key]):\n",
    "                                values.append(m[key])\n",
    "                        \n",
    "                        if values:\n",
    "                            avg_metrics[key] = float(np.mean(values))\n",
    "                        else:\n",
    "                            # Valori predefiniti per le metriche mancanti\n",
    "                            defaults = {'ssim': 0.5, 'psnr': 20.0, 'fid': 50.0, 'is_score': 2.0, 'lpips': 0.5}\n",
    "                            avg_metrics[key] = defaults.get(key, 0.0)\n",
    "                else:\n",
    "                    # Se non ci sono metriche valide, usa valori predefiniti\n",
    "                    avg_metrics = {'ssim': 0.5, 'psnr': 20.0, 'fid': 50.0, 'is_score': 2.0, 'lpips': 0.5}\n",
    "            else:\n",
    "                # Nessuna metrica calcolata, usa valori predefiniti\n",
    "                avg_metrics = {'ssim': 0.5, 'psnr': 20.0, 'fid': 50.0, 'is_score': 2.0, 'lpips': 0.5}\n",
    "            \n",
    "            result = {'val_loss': avg_loss, **avg_metrics}\n",
    "            \n",
    "            # Convalida che tutti i valori siano finiti\n",
    "            for key, value in result.items():\n",
    "                if not np.isfinite(value):\n",
    "                    logger.warning(f\"Invalid validation metric {key}: {value}\")\n",
    "                    defaults = {'val_loss': 1.0, 'ssim': 0.5, 'psnr': 20.0, 'fid': 50.0, 'is_score': 2.0, 'lpips': 0.5}\n",
    "                    result[key] = defaults.get(key, 0.0)\n",
    "            \n",
    "            self.model.train()\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in validation: {e}\")\n",
    "            self.model.train()\n",
    "            return {'val_loss': 1.0, 'ssim': 0.5, 'psnr': 20.0, 'fid': 50.0, 'is_score': 2.0, 'lpips': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702d88b",
   "metadata": {},
   "source": [
    "#  Salvataggio Checkpoint\n",
    " \n",
    " Il metodo `save_checkpoint()` (righe 444-470) salva lo stato completo del training:\n",
    " \n",
    " **Contenuto checkpoint** (righe 446-457):\n",
    " - Numero epoca corrente\n",
    " - State dict del modello (pesi e parametri)\n",
    " - State dict dell'ottimizzatore (momentum, learning rate)\n",
    " - Metriche di validazione dell'epoca\n",
    " - Configurazione completa del progetto\n",
    " - Se adversarial: anche discriminatore e suo ottimizzatore\n",
    " \n",
    " **Due tipi di salvataggio**:\n",
    " 1. **Checkpoint regolare**: Salvato ogni N epoche per recovery\n",
    " 2. **Best model**: Salvato solo quando validation loss migliora\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['training']['save_every']`: frequenza salvataggio (20 epoche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(self, epoch: int, val_metrics: Dict, is_best: bool = False):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    try:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_g_state_dict': self.optimizer_g.state_dict(),\n",
    "            'val_metrics': val_metrics,\n",
    "            'config': self.config\n",
    "        }\n",
    "        \n",
    "        if self.use_adversarial:\n",
    "            checkpoint['discriminator_state_dict'] = self.discriminator.state_dict()\n",
    "            checkpoint['optimizer_d_state_dict'] = self.optimizer_d.state_dict()\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = self.checkpoint_dir / f'checkpoint_epoch_{epoch}.pt'\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = self.checkpoint_dir / 'best_model.pt'\n",
    "            torch.save(checkpoint, best_path)\n",
    "            logger.info(f\"Saved best model with val_loss: {val_metrics['val_loss']:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f77590",
   "metadata": {},
   "source": [
    "#  Generazione Campioni per Monitoraggio\n",
    " \n",
    " Il metodo `generate_samples()` (righe 472-515) genera immagini di esempio durante il training:\n",
    " \n",
    " **Scopo**: Monitorare visivamente il progresso del modello attraverso le epoche\n",
    " \n",
    " **Sample texts predefiniti** (righe 478-487): 8 descrizioni diverse che coprono vari tipi di Pokemon:\n",
    " - Pokemon elettrico (Pikachu-like)\n",
    " - Pokemon acquatico (Blastoise-like)  \n",
    " - Pokemon drago (Charizard-like)\n",
    " - Pokemon pianta (Venusaur-like)\n",
    " - E altri tipi per diversità\n",
    " \n",
    " **Processo** (righe 491-510):\n",
    " 1. Modello in eval mode\n",
    " 2. Genera immagine per ogni descrizione  \n",
    " 3. Salva ogni immagine singolarmente\n",
    " 4. Ritorna modello a train mode\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['training']['sample_every']`: frequenza generazione campioni (5 epoche)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(self, epoch: int, num_samples: int = 8):\n",
    "        \"\"\"Generate and save sample images\"\"\"\n",
    "        try:\n",
    "            self.model.eval()\n",
    "            \n",
    "            # Descrizione dei campioni\n",
    "            sample_texts = [\n",
    "                \"A small yellow electric mouse Pokemon with red cheeks and a lightning bolt tail\",\n",
    "                \"A large blue turtle Pokemon with water cannons on its shell\",\n",
    "                \"An orange dragon Pokemon that breathes fire and has wings\",\n",
    "                \"A green plant Pokemon with a large flower on its back\",\n",
    "                \"A purple ghost Pokemon with a mischievous smile\",\n",
    "                \"A pink fairy Pokemon with ribbons and bows\",\n",
    "                \"A steel bird Pokemon with sharp metallic feathers\",\n",
    "                \"A dark wolf Pokemon with red eyes and sharp claws\"\n",
    "            ][:num_samples]\n",
    "            \n",
    "            generated_images = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, text in enumerate(sample_texts):\n",
    "                    try:\n",
    "                        # Genera l'immagine\n",
    "                        image = self.model.generate(text, device=self.device)\n",
    "                        generated_images.append(image)\n",
    "                        \n",
    "                        # Salva la singola immagine\n",
    "                        img = Image.fromarray(image)\n",
    "                        img.save(self.samples_dir / f'epoch_{epoch}_sample_{i}.png')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Error generating sample {i}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            if generated_images:\n",
    "                logger.info(f\"Generated {len(generated_images)} samples for epoch {epoch}\")\n",
    "            \n",
    "            self.model.train()\n",
    "            return self.samples_dir / f'epoch_{epoch}_samples'\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating samples: {e}\")\n",
    "            self.model.train()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a60e88",
   "metadata": {},
   "source": [
    "#  Loop Principale di Training\n",
    " \n",
    " Il metodo `train()` (righe 517-628) orchestra l'intero processo di training:\n",
    " \n",
    " **Struttura del loop principale**:\n",
    " 1. **Loop epoche** (righe 526-527): Itera attraverso tutte le epoche\n",
    " 2. **Training loop** (righe 530-557): Training su tutti i batch\n",
    " 3. **Progress monitoring** (righe 560-569): Aggiorna progress bar e log metriche\n",
    " 4. **Validation** (righe 572-584): Ogni N epoche secondo config\n",
    " 5. **Early stopping** (righe 604-606): Se validation non migliora per N epoche\n",
    " 6. **Sample generation** (righe 609-614): Genera esempi per monitoraggio visivo\n",
    " \n",
    " **Gestione errori robusta**:\n",
    " - Continue se singolo batch fallisce\n",
    " - KeyboardInterrupt per stop manuale\n",
    " - Finally block per cleanup (chiude writer, W&B)\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['training']['validate_every']`: frequenza validazione (5 epoche)\n",
    " - `config['training']['patience']`: pazienza per early stopping (80 epoche)\n",
    " - `config['logging']['log_every']`: frequenza logging (10 step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18740194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, train_loader, val_loader, num_epochs: int):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        logger.info(f\"Starting training for {num_epochs} epochs\")\n",
    "        logger.info(f\"Device: {self.device}\")\n",
    "        logger.info(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        global_step = 0\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(1, num_epochs + 1):\n",
    "                logger.info(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "                \n",
    "                # Training loop\n",
    "                epoch_losses = []\n",
    "                progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\")\n",
    "                \n",
    "                for batch_idx, batch in enumerate(progress_bar):\n",
    "                    try:\n",
    "                        # Training step\n",
    "                        losses = self.train_step(batch)\n",
    "                        epoch_losses.append(losses)\n",
    "                        \n",
    "                        # Aggiorna la progress bar\n",
    "                        progress_bar.set_postfix({k: f\"{v:.4f}\" for k, v in losses.items()})\n",
    "                        \n",
    "                        # Logging\n",
    "                        if global_step % self.config['logging']['log_every'] == 0:\n",
    "                            for key, value in losses.items():\n",
    "                                self.writer.add_scalar(f'train/{key}', value, global_step)\n",
    "                            \n",
    "                            if self.config['logging'].get('use_wandb', False):\n",
    "                                try:\n",
    "                                    wandb.log({f'train/{k}': v for k, v in losses.items()}, step=global_step)\n",
    "                                except Exception as e:\n",
    "                                    logger.debug(f\"W&B logging failed: {e}\")\n",
    "                        \n",
    "                        global_step += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Error in training batch {batch_idx}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # Media delle perdite dell'epoca\n",
    "                if epoch_losses:\n",
    "                    avg_losses = {}\n",
    "                    for key in epoch_losses[0].keys():\n",
    "                        values = [loss.get(key, 0.0) for loss in epoch_losses if isinstance(loss, dict)]\n",
    "                        avg_losses[key] = float(np.mean(values)) if values else 0.0\n",
    "                    \n",
    "                    logger.info(f\"Epoch {epoch} - Average losses: {avg_losses}\")\n",
    "                else:\n",
    "                    logger.warning(f\"No valid losses for epoch {epoch}\")\n",
    "                    continue\n",
    "                \n",
    "                # Validation\n",
    "                if epoch % self.config['training']['validate_every'] == 0:\n",
    "                    val_metrics = self.validate(val_loader)\n",
    "                    logger.info(f\"Validation metrics: {val_metrics}\")\n",
    "                    \n",
    "                    # Validation metrics logging\n",
    "                    for key, value in val_metrics.items():\n",
    "                        self.writer.add_scalar(f'val/{key}', value, epoch)\n",
    "                    \n",
    "                    if self.config['logging'].get('use_wandb', False):\n",
    "                        try:\n",
    "                            wandb.log({f'val/{k}': v for k, v in val_metrics.items()}, step=global_step)\n",
    "                        except Exception as e:\n",
    "                            logger.debug(f\"W&B validation logging failed: {e}\")\n",
    "                    \n",
    "                    # Schedulazione learning rate\n",
    "                    self.scheduler_g.step(val_metrics['val_loss'])\n",
    "                    if self.use_adversarial:\n",
    "                        self.scheduler_d.step(val_metrics['val_loss'])\n",
    "                    \n",
    "                    # Controlla se il modello è il migliore\n",
    "                    is_best = val_metrics['val_loss'] < self.best_val_loss\n",
    "                    if is_best:\n",
    "                        self.best_val_loss = val_metrics['val_loss']\n",
    "                        self.patience_counter = 0\n",
    "                    else:\n",
    "                        self.patience_counter += 1\n",
    "                    \n",
    "                    # Salva il checkpoint\n",
    "                    if epoch % self.config['training']['save_every'] == 0 or is_best:\n",
    "                        self.save_checkpoint(epoch, val_metrics, is_best)\n",
    "                    \n",
    "                    # Stop anticipato\n",
    "                    if self.patience_counter >= self.config['training']['patience']:\n",
    "                        logger.info(f\"Early stopping triggered after {epoch} epochs\")\n",
    "                        break\n",
    "                \n",
    "                # Genera esempi\n",
    "                if epoch % self.config['training']['sample_every'] == 0:\n",
    "                    sample_path = self.generate_samples(epoch)\n",
    "                    if sample_path:\n",
    "                        logger.info(f\"Generated samples saved to {sample_path}\")\n",
    "            \n",
    "            logger.info(\"Training completed successfully!\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"Training interrupted by user\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self.writer.close()\n",
    "            if self.config['logging'].get('use_wandb', False):\n",
    "                try:\n",
    "                    wandb.finish()\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a5b0f",
   "metadata": {},
   "source": [
    "#  Funzione Train Model - Entry Point\n",
    " \n",
    " La funzione `train_model()` (righe 630-652) è il punto di ingresso principale per il training:\n",
    " \n",
    " **Setup iniziale** (righe 632-633):\n",
    " - Imposta seed per riproducibilità usando config seed (42)\n",
    " - Garantisce risultati consistenti tra run diversi\n",
    " \n",
    " **Creazione componenti** (righe 635-642):\n",
    " - Crea dataloaders usando la funzione dal preprocessing\n",
    " - Usa il tokenizer specificato in config per consistency\n",
    " - Istanzia la classe Trainer con tutta la configurazione\n",
    " \n",
    " **Avvio training** (righe 645-651):\n",
    " - Chiama il metodo train con train/val loader\n",
    " - Usa numero epoche da config\n",
    " - Ritorna trainer instance per analisi post-training\n",
    " \n",
    " **Parametri config utilizzati**:\n",
    " - `config['project']['seed']`: seed riproducibilità (42)\n",
    " - `config['model']['encoder']['model_name']`: tokenizer name (\"prajjwal1/bert-mini\")\n",
    " - `config['training']['num_epochs']`: numero epoche totali (300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config: Dict):\n",
    "    # Setta seeds casuali\n",
    "    torch.manual_seed(config['project']['seed'])\n",
    "    np.random.seed(config['project']['seed'])\n",
    "    \n",
    "    # Crea dataloaders\n",
    "    dataloaders = create_dataloaders(\n",
    "        config,\n",
    "        tokenizer_name=config['model']['encoder']['model_name']\n",
    "    )\n",
    "    \n",
    "    # Crea trainer\n",
    "    trainer = Trainer(config)\n",
    "    \n",
    "    # Addestra il modello\n",
    "    trainer.train(\n",
    "        train_loader=dataloaders['train'],\n",
    "        val_loader=dataloaders['val'],\n",
    "        num_epochs=config['training']['num_epochs']\n",
    "    )\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba611428",
   "metadata": {},
   "source": [
    "#  Script di Test del Training\n",
    " \n",
    " Il blocco finale (righe 654-660) permette di testare il training quando si esegue il file direttamente:\n",
    " \n",
    " **Test eseguiti**:\n",
    " 1. **Caricamento config**: Legge configurazione da configs/config.yaml\n",
    " 2. **Avvio training completo**: Esegue train_model() con config reale\n",
    " 3. **Monitoraggio**: Tutti i log, checkpoints, samples vengono generati\n",
    " \n",
    " Questo è utile per:\n",
    " - Testare l'intero pipeline di training\n",
    " - Debug di configurazioni diverse\n",
    " - Avvio training standalone senza main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import yaml\n",
    "    \n",
    "    with open('configs/config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    trainer = train_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9967724",
   "metadata": {},
   "source": [
    "#  Riepilogo Parametri Config Utilizzati\n",
    " \n",
    " Il file `trainer.py` utilizza quasi tutti i parametri dal file `config.yaml`:\n",
    " \n",
    " **Sezione `training`**:\n",
    " - `learning_rate`: Learning rate ottimizzatori (0.0001)\n",
    " - `beta1`, `beta2`: Parametri Adam optimizer (0.0, 0.99)\n",
    " - `num_epochs`: Numero epoche totali (300)\n",
    " - `batch_size`: Dimensione batch (2) - usato nei dataloaders\n",
    " - `validate_every`: Frequenza validazione (5 epoche)\n",
    " - `save_every`: Frequenza salvataggio checkpoint (20 epoche)\n",
    " - `sample_every`: Frequenza generazione campioni (5 epoche)\n",
    " - `patience`: Pazienza early stopping (80 epoche)\n",
    " \n",
    " **Sezione `loss`**:\n",
    " - `reconstruction_weight`: Peso L1 loss (15.0)\n",
    " - `perceptual_weight`: Peso LPIPS loss (2.5)\n",
    " - `adversarial_weight`: Peso adversarial loss (0.5)\n",
    "\n",
    " \n",
    " **Sezione `logging`**:\n",
    " - `log_every`: Frequenza logging TensorBoard (10 steps)\n",
    " - `use_wandb`: Abilita Weights & Biases (false)\n",
    " - `project_name`: Nome progetto W&B (\"pikapika-high-quality-v2\")\n",
    " \n",
    " **Sezione `paths`**:\n",
    " - `checkpoints_dir`: Directory checkpoint (\"data/models/checkpoints_hq_v2\")\n",
    " - `samples_dir`: Directory samples (\"outputs/samples_hq_v2\")\n",
    " - `logs_dir`: Directory logs TensorBoard (\"logs\")\n",
    " \n",
    " **Sezione `project`**:\n",
    " - `device`: Dispositivo preferito (\"cpu\")\n",
    " - `seed`: Seed riproducibilità (42)\n",
    "\n",
    "#  Conclusioni - Sistema di Training PikaPikaGenerator\n",
    " \n",
    " Il sistema di training implementato in `trainer.py` è completo e production-ready:\n",
    " \n",
    "  **Metriche di Valutazione**:\n",
    " - **SSIM**: Similarità strutturale immagini\n",
    " - **PSNR**: Qualità ricostruzione pixel-wise  \n",
    " - **LPIPS**: Similarità percettuale deep learning\n",
    " - **FID/IS**: Qualità distribuzione immagini generate\n",
    "  **Workflow Completo**:\n",
    " 1. **Setup**: Directories, model, optimizers, losses\n",
    " 2. **Training Loop**: Batch processing con progress monitoring\n",
    " 3. **Validation**: Calcolo metriche comprehensive ogni N epoche  \n",
    " 4. **Checkpointing**: Salvataggio automatico migliori modelli\n",
    " 5. **Sample Generation**: Monitoring visivo progresso\n",
    " 6. **Early Stopping**: Terminazione intelligente training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
